---
title: "PEP2INF"
author: "Gabriel Cabrera"
date: "2025-06-29"
output: html_document
---

### PRUEBA YUEN DOS MUESTRAS INDEPENDIENTES

Comparar dos medias independientes 
  - cuando los datos no cumplen con la condición de normalidad
  - datos atípicos
  - varianzas diferentes
  - tamaños dispares.

CONDICIONES:

	- Las observaciones en una muestra son independientes
 	- Las muestras son independientes
	- Variables escala intervalos iguales

OTRAS CONDICIONES:
  - Las poblaciones de origen no son extremadamente diferentes. (en extremos)
  - El impacto de los valores extremos no es de interés de la investigación.
  - El nivel de poda no está cerca del nivel de la mediana, siendo γ ≈ 0,2 un valor frecuente.
  - Las muestras no son demasiado reducidas. 5 por muestra es un valor mínimo.
  
  
```{r}
library(ggpubr)
library(WRS2)

# Construir la matriz de datos
a <- c(25.1, 25.2, 25.3, 25.3, 25.4, 25.4, 25.5, 25.5, 25.6, 25.8, 25.8, 
       25.9, 25.9, 26.0, 26.0, 26.2, 26.2, 26.2, 26.3, 26.4, 26.5, 26.5, 
       26.6, 26.7, 26.7, 26.9, 26.9, 27.0, 27.1, 27.3, 27.8, 28.4, 28.5, 
       29.0, 29.8, 30.2, 31.8, 31.9, 33.3, 33.7)

b <- c(24.1, 24.4, 24.4, 24.5, 24.7, 24.8, 24.8, 25.1, 25.2, 25.2, 25.2, 
       25.3, 25.4, 25.7, 25.7, 26.3, 26.3, 26.4, 26.5, 27.2, 27.7, 28.3, 
       28.4, 28.4, 28.6, 28.7, 29.6, 29.9, 30.1, 30.5)

Tiempo <- c(a, b)
Algoritmo <- c(rep("A", length(a)), rep("B", length(b)))
datos <- data.frame(Tiempo, Algoritmo)

# Comprobar normalidad
qq <- ggqqplot(datos, x = "Tiempo", facet.by = "Algoritmo",
               palette = c("steelblue", "steelblue1"), color = "Algoritmo",
               xlab = "Cuantil teórico", ylab = "Tiempo de ejecución [ms]")
qq <- qq + theme(legend.position = "none")

print(qq)

#Aplicar una poda del 20% a las muestras
gamma <- 0.2
n_a <- length(a)
n_b <- length(b)
poda_a <- floor(n_a * gamma)
poda_b <- floor(n_b * gamma)

a_trunc <- a[poda_a:(n_a - poda_a)]
b_trunc <- b[poda_b:(n_b - poda_b)]

Tiempo_t <- c(a_trunc, b_trunc)
Algoritmo_t <- c(rep("A", length(a_trunc)), rep("B", length(b_trunc)))
datos_t <- data.frame(Tiempo_t, Algoritmo_t)

qq_t <- ggqqplot(datos_t, x = "Tiempo_t", facet.by = "Algoritmo_t",
                 palette = c("steelblue", "steelblue1"), color = "Algoritmo_t",
                 xlab = "Cuantil teórico",
                 ylab = "Tiempo de ejecución truncado [ms]")
qq_t <- qq_t + theme(legend.position = "none")
print(qq_t)

# Aplicar y mostrar la prueba de Yuen asintótica
prueba <- yuen(Tiempo ~ Algoritmo, data = datos, tr = gamma)
cat("\nPrueba de Yuen para dos muestras independientes\n")
cat("----------------------------------------------\n")
print(prueba)

# Establecer cantidad de repeticiones con bootstrapping
B <- 999

# Aplicar la prueba de Yuen con bootstrapping y la media
set.seed(135)
prueba_media <- pb2gen(Tiempo ~ Algoritmo, data = datos, est="mean", nboot=B)

# Aplicar la prueba de Yuen con bootstrapping y la mediana
set.seed(135)
prueba_mediana <- pb2gen(Tiempo ~ Algoritmo, data = datos, est="median", nboot=B)

# Mostrar los resultados
cat("\nPrueba de Yuen - implementación con bootstrapping\n")
cat("=================================================\n")

cat("\nResultado al usar bootstrapping y la media como estimador\n")
cat("---------------------------------------------------------\n")
print(prueba_media)
cat("\nResultado al usar bootstrapping y la mediana como estimador\n")
cat("-----------------------------------------------------------\n")
print(prueba_mediana)
```
### YUEN PARA DOS MUESTRAS PAREADAS
Comparar dos medias pareadas 
  - cuando los datos no cumplen con la condición de normalidad
  - datos atípicos
  - observaciones independintes
  - variable de intervalos iguales
  
CONDICIONES PARA MUESTRAS INDEPENDIENTES:
  - Las diferencias siguen una distribución relativamente simétrica
  - La poda que se aplica elimina valores atípicos extremos.
  - Nivel de poda no es cercano a la mediana
  - Las muestras no son demasiado reducidas. 5 min.
  
  
```{r}
library(ggpubr)
library(WRS2)

# Construir las estructuras con los datos observados
a <- c(32.3, 32.0, 32.0, 36.0, 34.2, 32.7, 32.5, 32.0, 32.1, 33.4, 
       32.3, 37.2, 32.1, 32.0, 33.9, 34.1, 36.6, 34.5, 32.7, 33.1, 
       32.7, 32.1, 36.7, 32.2, 38.0)

b <- c(35.3, 20.1, 18.6, 46.3, 42.1, 39.3, 37.0, 28.0, 30.2, 40.4, 
       35.6, 50.7, 33.6, 17.9, 41.0, 41.6, 47.8, 43.2, 38.3, 39.9, 
       38.0, 28.3, 48.4, 34.7, 52.9)

dif <- a - b

# Aplicar una poda del 20% al conjunto de diferencias
gamma <- 0.2
n <- length(dif)
poda <- floor(n * gamma)
dif_s <- sort(dif) # 'dif_s' para evitar sobrescribir 'dif' antes de que se use para 'yuenD'
dif_trunc <- dif_s[(poda + 1):(n - poda)]
n_t <- length(dif_trunc)

# Obtener gráficos Q-Q de las diferencias originales y podadas
datos <- data.frame(Diferencia = c(dif, dif_trunc),
                    Muestra = c(rep("Original", n), rep("Podados", n_t)))
qq <- ggqqplot(datos, x = "Diferencia", facet.by = "Muestra",
               palette = c("steelblue", "steelblue1"), color = "Muestra",
               xlab = "Cuantil teórico",
               ylab = "Diferencias en tiempos de ejecución [ms]")
qq <- qq + theme(legend.position = "none")
print(qq)

# Aplicar y mostrar la prueba de Yuen para muestras apareadas
gamma <- 0.2 # Redefinir gamma por si acaso, aunque ya está definida
prueba <- yuend(x = a, y = b, tr = gamma)
cat("Prueba de Yuen para dos muestras pareadas\n")
cat("-----------------------------------------\n")
print(prueba)

```

### Análisis robusto de una vía para muestras independientes
Alternativa para ANOVA de una vía para muestras independientes.
  - tamaño muestral muy diferentes
  - no se cumple con la homocedasticidad
  
CONDICIONES:
  - Las observaciones en una muestra son independientes
  - Las muestras son independientes
  - Variables escala intervalos iguales


- t1way(formula, data, tr, alpha) efectúa un procedimiento similar a ANOVA usando medias truncadas
- t1waybt(formula, data, tr, nboot) realiza un procedimiento análogo al anterior incorporando bootstrapping.
- med1way(formula, data, iter), que emplea la mediana y sigue un proceso
iterativo

```{r}
library(ggpubr)
library(WRS2)

# Construir las estructuras con los datos
A <- c(25.1, 25.2, 25.3, 25.3, 25.4, 25.4, 25.5, 25.5, 25.6, 25.8, 25.8, 
       25.9, 25.9, 26.0, 26.0, 26.2, 26.2, 26.2, 26.3, 26.4, 26.5, 26.5, 
       26.6, 26.7, 26.7, 26.9, 26.9, 27.0, 27.1, 27.3, 27.8, 28.4, 28.5, 
       29.0, 29.8, 30.2, 31.8, 31.9, 33.3, 33.7)

B <- c(24.1, 24.4, 24.4, 24.5, 24.7, 24.8, 24.8, 25.1, 25.2, 25.2, 25.2, 
       25.3, 25.4, 25.7, 25.7, 26.3, 26.3, 26.4, 26.5, 27.2, 27.7, 28.3, 
       28.4, 28.4, 28.6, 28.7, 29.6, 29.9, 30.1, 30.5)

C <- c(24.5, 24.5, 24.5, 24.5, 24.5, 24.6, 24.6, 24.6, 24.6, 24.6, 
       24.6, 24.7, 24.7, 24.7, 24.7, 24.8, 25.0, 25.0, 25.0, 25.2, 25.2, 
       25.2, 25.2, 25.5, 25.7, 25.9, 26.2, 26.5, 26.5, 26.7, 27.0, 29.2, 
       29.9, 30.1)

Tiempo <- c(A, B, C)
Algoritmo <- c(rep("A", length(A)), rep("B", length(B)), rep("C", length(C)))
Algoritmo <- factor(Algoritmo) # Asegurarse de que Algoritmo sea un factor
datos <- data.frame(Tiempo, Algoritmo)

# Obtener gráficos Q-Q de las muestras
qq <- ggqqplot(datos, x = "Tiempo", facet.by = "Algoritmo", color = "Algoritmo",
               palette = c("steelblue", "steelblue1", "steelblue4"),
               xlab = "Cuantil teórico", ylab = "Tiempos de ejecución [ms]")
qq <- qq + theme(legend.position = "none")
print(qq)

# Fijar nivel de significación, nivel de poda y nro. de iteraciones bootstrap
alfa <- 0.05
gamma <- 0.2
nboot <- 999

# Comparar los diferentes algoritmos usando medias truncadas
set.seed(666)
una_via <- t1way(Tiempo ~ Algoritmo, data = datos,
                 tr = gamma, alpha = alfa, nboot = nboot) # nboot aquí no es para el p-valor, sino para los CIs si t1way los calcula por bootstrapping internamente. Para el p-valor asintótico, nboot no se usa.

cat("Análisis de una vía para muestras independientes (asintótico)\n")
cat("-----------------------------------------------------------\n")
print(una_via)

if (una_via[["p.value"]] < alfa) {
  una_via_ph <- lincon(Tiempo ~ Algoritmo, data = datos,
                       tr = gamma, alpha = alfa)
  
  cat("Análisis post-hoc para muestras independientes (asintótico)\n")
  cat("----------------------------------------------------------\n")
  print(una_via_ph)
}

# Comparar los diferentes algoritmos usando medias truncadas y bootstrapping
set.seed(666)
una_via_bt <- t1waybt(Tiempo ~ Algoritmo, data = datos,
                      tr = gamma, nboot = nboot)

cat("Análisis de una vía para muestras independientes (bootstrapped)\n")
cat("-----------------------------------------------------------------\n")
print(una_via_bt)

if (una_via_bt[["p.value"]] < alfa) {
  set.seed(666) # Restablecer la semilla para la reproducibilidad del post-hoc
  una_via_bt_ph <- mcppb20(Tiempo ~ Algoritmo, data = datos,
                           tr = gamma, nboot = nboot)
  
  cat("Análisis post-hoc para muestras independientes (bootstrapped)\n")
  cat("-------------------------------------------------------------\n")
  print(una_via_bt_ph)
}
```
### Análisis robusto de una vía para muestras correlacionadas
Alternativa para ANOVA de una vía para muestras correlacionadas.
  - datos disponibles violan la condición de normalidad o de esfericidad
  
CONDICIONES: 
  - Los casos o bloques medidos son independientes entre sí
  - Se tiene un conjunto de mediciones (usualmente mayor a dos) para cada caso o bloque
  - Las variable medida tiene al menos escala de intervalos iguales

- rmanova(y, groups, blocks, tr) efectúa un procedimiento similar a ANOVA usando medias truncadas  
- rmanovab(y, groups, blocks, tr, nboot) realiza la misma tarea que rmanova(), incorporando bootstrapping
POST-HOC
- rmmcp(y, groups, blocks, tr, alpha) implementa el procedimiento posthoc para dicha prueba  
- pairdepb(y, groups, blocks, tr, nboot).   

```{r}
library(dplyr)
library(ggpubr)
library(tidyr)
library(WRS2)

# Construir las estructuras con los datos
A <- c(32.0, 32.0, 32.0, 32.0, 32.1, 32.1, 32.1, 32.2, 32.3, 32.3, 32.5, 
       32.7, 32.7, 32.7, 33.1, 33.4, 33.9, 34.1, 34.2, 34.5, 36.0, 36.6, 
       36.7, 37.2, 38.0)

B <- c(33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.3, 33.3, 33.3, 33.3, 33.5, 
       33.6, 33.7, 33.9, 33.9, 34.2, 34.2, 34.3, 34.3, 34.4, 34.5, 34.6, 
       34.6, 38.9, 40.2)

C <- c(32.0, 32.2, 32.5, 32.6, 32.7, 32.7, 32.7, 33.0, 33.2, 33.4, 33.6, 
       33.6, 33.9, 34.1, 34.2, 34.4, 34.4, 34.5, 34.6, 34.7, 36.3, 36.6, 
       36.7, 38.9, 39.2)

Instancia <- factor(1:length(A))
datos_anchos <- data.frame(Instancia, A, B, C)

# Llevar las matrices de datos a formato largo
pivot_longer_cols <- c("A", "B", "C")
datos <- datos_anchos %>%
  pivot_longer(cols = all_of(pivot_longer_cols), names_to = "Algoritmo", values_to = "Tiempo") %>%
  mutate(Algoritmo = factor(Algoritmo)) # Asegurarse de que Algoritmo sea un factor en el formato largo

# Calcular las diferencias y llevarlas a formato largo para los Q-Q plots
dif_A_B <- A - B
dif_A_C <- A - C
dif_B_C <- B - C # Asegúrate de que las diferencias sean consistentes (B-C o C-B)

# Crear un dataframe para las diferencias para los Q-Q plots
dif_df <- data.frame(
  Diferencia = c(dif_A_B, dif_A_C, dif_B_C),
  Algoritmos = c(rep("A - B", length(dif_A_B)), 
                 rep("A - C", length(dif_A_C)), 
                 rep("B - C", length(dif_B_C)))
) %>%
  mutate(Algoritmos = factor(Algoritmos))


# Obtener gráficos Q-Q de las diferencias
qq <- ggqqplot(dif_df, x = "Diferencia", facet.by = "Algoritmos",
               color = "Algoritmos",
               palette = c("steelblue", "steelblue1", "steelblue4"),
               xlab = "Cuantil teórico",
               ylab = "Diferencias en tiempos de ejecución [ms]")
qq <- qq + theme(legend.position = "none")
print(qq)

# Fijar nivel de significación y nivel de poda
alfa <- 0.05
gamma <- 0.2

# Comparar los algoritmos usando medias truncadas de las diferencias (asintótico)
mr_rob <- rmanova(y = datos[["Tiempo"]], groups = datos[["Algoritmo"]],
                  blocks = datos[["Instancia"]], tr = gamma)

cat("Análisis de una vía para medidas repetidas (asintótico)\n")
cat("------------------------------------------------------\n")
print(mr_rob)

if (mr_rob[["p.value"]] < alfa) {
  mr_rob_ph <- rmmcp(y = datos[["Tiempo"]], groups = datos[["Algoritmo"]],
                      blocks = datos[["Instancia"]], tr = gamma, alpha = alfa)
  
  cat("Análisis post-hoc para medidas repetidas (asintótico)\n")
  cat("----------------------------------------------------\n")
  print(mr_rob_ph)
}

# Fijar la cantidad de iteraciones bootstrap
nboot <- 999

# Comparar los algoritmos usando diferencias truncadas y bootstrapping
set.seed(666)
mr_bt <- rmanovab(y = datos[["Tiempo"]], groups = datos[["Algoritmo"]],
                  blocks = datos[["Instancia"]], tr = gamma, nboot = nboot)

cat("Análisis de una vía para medidas repetidas (bootstrapped)\n")
cat("---------------------------------------------------------\n")
print(mr_bt)

if (mr_bt[["test"]] > mr_bt[["crit"]]) { # La condición para el post-hoc en rmanovab usa test > crit
  set.seed(666)
  mr_bt_ph <- pairdepb(y = datos[["Tiempo"]], groups = datos[["Algoritmo"]],
                       blocks = datos[["Instancia"]], tr = gamma, nboot = nboot)
  
  cat("Análisis post-hoc para medidas repetidas (bootstrapped)\n")
  cat("-------------------------------------------------------\n")
  print(mr_bt_ph)
}

```
  
### REMUESTREO
alternativa a emplear cuando necesitamos inferir sobre parámetros distintos a la media o la proporción, o bien cuando no se cumplen los supuestos sobre la distribución de los datos (como normalidad u homocedasticidad) o el conocimiento de parámetros poblacionales (como la varianza) que hacen las pruebas paramétricas estudiadas.

  - La muestra original es representativa de la población
  - Las observaciones dentro de la muestra original son independientes.

Existen dos métodos principales de remuestreo:
1. **Bootstrap**: Consiste en tomar muestras con reemplazo del conjunto de datos original para crear nuevas muestras. Se utiliza para estimar la distribución de una estadística y calcular intervalos de confianza.
2. **Permutación**: Implica reordenar los datos de manera aleatoria para evaluar la significancia estadística de una prueba. Se utiliza para comparar grupos y evaluar la hipótesis nula.

### BOOTSTRAPPING PARA UNA MUESTRA

construir un intervalo de confianza para la media de la población,

```{r}
library(ggpubr)
library(WRS2)
library(boot)
library(bootES) 

# --- Script 12.12: construcción de un intervalo de confianza para la media poblacional mediante bootstrapping. ---

# Crear muestra inicial, mostrar su histograma y calcular la media
muestra <- c(79, 75, 84, 75, 94, 82, 76, 90, 79, 88)

# Histograma de la muestra (opcional, no está en el script pero es buena práctica)
hist(muestra, main = "Histograma de la Muestra Inicial", xlab = "Valores")

# Calcular la media de la muestra inicial
media_inicial <- mean(muestra)
cat("Media de la muestra inicial:", media_inicial, "\n")

# Establecer cantidad de remuestreos y nivel de significación
B <- 2000
alfa <- 0.01

# Función para calcular el estadístico: media de la remuestra
media <- function(valores, i) {
  mean(valores[i])
}

# Construir la distribución bootstrap usando el paquete boot
set.seed(432)
distribucion_b <- boot(muestra, statistic = media, R = B)

# Mostrar y graficar la distribución bootstrap
print(distribucion_b)
plot(distribucion_b)

# Construir y mostrar los intervalos de confianza
# (usando conf = 1 - alfa para el nivel de confianza)
ics <- boot.ci(distribucion_b, conf = 1 - alfa,
               type = c("norm", "perc", "bca"))

cat("\n") # Salto de línea
print(ics)


# --- Script 12.13: uso de la función bootES() para aplicar bootstrapping al ejemplo. ---
# NOTA: Este script utiliza la misma 'muestra', 'B' y 'alfa' definidos anteriormente.
# bootES se utiliza aquí para una demostración alternativa de bootstrapping y CI.

# Construir la distribución bootstrap usando el paquete bootES
# (esta llamada además calcula (solo) un intervalo de confianza y grafica la distribución bootstrap).
set.seed(432) # Se usa la misma semilla para reproducibilidad
distribucion_bES <- bootES(muestra, R = B, ci.type = "bca",
                            ci.conf = 1 - alfa, plot = TRUE) # Nota: ci.conf es el nivel de confianza, no el nivel de significancia

# Mostrar bootstrap obtenida con bootES
print(distribucion_bES)


# --- Script 12.14: obtención del valor p basado en bootstrapping para el ejemplo. ---
# NOTA: Este script usa 'distribucion_b' (del paquete 'boot')

# Desplazar la distribución bootstrap para que se centre en el valor nulo
# Asumiendo que el valor nulo es una media hipotética (ej. 75)
valor_nulo <- 75 
desplazamiento <- mean(distribucion_b[["t"]]) - valor_nulo
distribucion_nula <- distribucion_b[["t"]] - desplazamiento

# Determinar y mostrar la media observada y el valor p
# La media observada se calcula sobre la muestra original
# Asegúrate de que 'media' es la función definida anteriormente o la media directamente
valor_observado <- mean(muestra) # O usa la función: media(muestra, 1:length(muestra))
                                 # La línea del script usa 'media(muestra, 1:length(muestra))' que llama a la función 'media' definida.
                                 # Ambas son equivalentes aquí, ya que 'media' es solo 'mean'.

# Cálculo del valor p basado en el desplazamiento de la distribución bootstrap
# Este es un método para calcular un p-valor bootstrap para una hipótesis de una cola
# (en este caso, si la media observada es mayor que la media nula).
# Se utiliza el método empírico que cuenta cuántas veces el estadístico desplazado
# es más extremo que el estadístico observado.
# Se añade +1 al numerador y denominador para evitar p-valores de cero, lo que se llama "corrección de Efron".
p <- (sum(distribucion_nula >= valor_observado) + 1) / (B + 1) # Usé '>=' para una hipótesis de una cola

cat("Media observada:", valor_observado, "\n")
cat("Valor p:", p, "\n")
```

###  Bootstrapping para dos muestras independientes
Si tenemos dos muestras independientes A y B provenientes de dos poblaciones diferentes, de tamaños nA y nB respectivamente

Tras aplicar pruebas de Shapiro-Wilk, los investigadores han comprobado que las notas de los varones no
siguen una distribución normal (W = 0,884, p = 0,006), por lo que han decidido usar bootstrapping para la
prueba de hipótesis, con un nivel de significación α = 0,05 y B = 9.999 repeticiones.

```{r}
# Script 12.15: bootstraping para la diferencia de dos medias del ejemplo.

library(boot)
library(ggpubr)
library(simpleboot)

# Definir las muestras obtenidas
hombres <- c(1.3, 1.5, 1.6, 1.7, 1.7, 1.9, 2.3, 2.4, 2.6, 2.6, 2.7, 2.8, 3.2, 3.7,
             4.1, 4.4, 4.5, 4.8, 5.2, 5.2, 5.3, 5.5, 5.5, 5.6, 5.6, 5.7, 5.7)
mujeres <- c(3.5, 3.6, 3.8, 4.3, 4.5, 4.5, 4.9, 5.1, 5.3, 5.3, 5.5,
             5.8, 6.0, 6.3, 6.3, 6.4, 6.4, 6.6, 6.7)
n_hombres <- length(hombres)
n_mujeres <- length(mujeres)

# Comprobar la normalidad de las muestras
cat("Comprobación de normalidad (Shapiro-Wilk):\n")
shapiro_hombres <- shapiro.test(hombres)
shapiro_mujeres <- shapiro.test(mujeres)

print(shapiro_hombres)
print(shapiro_mujeres)

# Verificar si las muestras no siguen una distribución normal
alpha_normality <- 0.05 # Nivel de significancia para la prueba de normalidad

if (shapiro_hombres$p.value < alpha_normality || shapiro_mujeres$p.value < alpha_normality) {
  cat("\nAl menos una de las muestras no sigue una distribución normal (p <", alpha_normality, "). Procediendo con bootstrapping.\n\n")

  # Calcular y mostrar la diferencia observada entre las medias muestrales
  media_hombres <- mean(hombres)
  media_mujeres <- mean(mujeres)
  diferencia_obs <- media_hombres - media_mujeres

  cat("Media hombres:", round(media_hombres,3), "\n")
  cat("Media mujeres:", round(media_mujeres,3), "\n")
  cat("Diferencia observada:", round(diferencia_obs, 3), "\n\n")

  # Crear la distribución bootstrap
  B <- 9999
  set.seed(432)
  distribucion_b <- two.boot(hombres, mujeres, FUN = mean, R = B)

  # Examinar la distribución bootstrap
  datos <- data.frame(diferencias = distribucion_b[["t"]])
  g_hist <- gghistogram(datos, x = "diferencias", bins = 100,
                        xlab = "Diferencia de medias", ylab = "Frecuencia")
  g_qq <- ggqqplot(datos, x = "diferencias")
  g <- ggarrange(g_hist, g_qq)
  print(g)

  media_b <- mean(datos[["diferencias"]])
  sd_b <- sd(datos[["diferencias"]])

  cat("Distribución bootstrap:\n")
  cat("\tMedia:", round(media_b, 3), "\n")
  cat("\tDesviación estándar:", round(sd_b, 3), "\n\n")

  # Construir y mostrar los intervalos de confianza
  alfa <- 0.05
  intervalo_bca <- boot.ci(distribucion_b, conf = 1 - alfa, type = "bca")
  print(intervalo_bca)

  # Desplazar la distribución bootstrap para reflejar la hipótesis nula
  valor_nulo <- -0.5
  desplazamiento <- media_b - valor_nulo
  distribucion_nula <- datos[["diferencias"]] - desplazamiento

  # Determinar y mostrar el valor p
  p <- (sum(distribucion_nula < diferencia_obs) + 1) / (B + 1)
  cat("\nValor p:", p, "\n")

} else {
  cat("\nAmbas muestras siguen una distribución normal (p >=", alpha_normality, "). Bootstrapping podría no ser estrictamente necesario, pero se puede usar para robustez.\n")
  # You can choose to proceed with bootstrapping here as well if desired for robustness,
  # or recommend parametric tests if normality assumptions are met.
}
```
### Bootstrapping para dos muestras apareadas
A partir de las dos muestras originales, se crea una nueva muestra con la diferencia entre ambas, y luego se realiza el proceso especificado para la construcción de un intervalo de confianza para el caso de una única muestra que ya conocimos.

```{r}
# Script 12.16: bootstraping para inferir acerca de la media de las diferencias.

library(bootES)
library(simpleboot)
set.seed(432)

# Ingresar datos originales.
prueba_1 <- c(3.5, 2.7, 1.0, 1.8, 1.6, 4.3, 5.8, 6.4, 3.9, 4.3, 3.4,
              5.3, 5.8, 5.3, 2.0, 1.3, 4.0, 5.3, 1.6, 3.6)

prueba_2 <- c(5.2, 5.1, 5.9, 4.8, 1.4, 2.3, 6.8, 5.3, 3.1, 3.8, 4.6,
              1.2, 3.9, 2.0, 1.7, 3.3, 6.0, 4.8, 6.9, 1.3)

shappiro_prueba_1 <- shapiro.test(prueba_1)
shappiro_prueba_2 <- shapiro.test(prueba_2)
cat("Prueba de Shapiro-Wilk para prueba_1:\n")
print(shappiro_prueba_1)
cat("\nPrueba de Shapiro-Wilk para prueba_2:\n")
print(shappiro_prueba_2)

# Calcular la diferencia entre ambas observaciones
diferencia <- prueba_2 - prueba_1

# Calcular la media observada de las diferencias.
valor_observado <- mean(diferencia)

# Generar la distribución bootstrap y su intervalo de confianza.
B <- 3999
alfa <- 0.05

distribucion_bES <- bootES(diferencia, R = B, ci.type = "bca",
                           ci.conf = 1 - alfa, plot = FALSE)

# Desplazar la distribución bootstrap para reflejar la hipótesis nula.
valor_nulo <- 0.5
desplazamiento <- mean(distribucion_bES[["t"]]) - valor_nulo
distribucion_nula <- distribucion_bES[["t"]] - desplazamiento

# Determinar el valor p.
p <- (sum(abs(distribucion_nula) > abs(valor_observado)) + 1) / (B + 1)

# Mostrar los resultados
cat("Media de la diferencia observada:", round(valor_observado, 3), "\n\n")
cat("Distribución bootstrap e intervalo de confianza:\n")
print(distribucion_bES)
cat("\nValor p:", round(p, 3), "\n")
```
### PRUEBA DE PERMUTACIONES (MONTE CARLO)
Las pruebas exactas de permutaciones para la diferencia entre dos grupos A y B

  - muestreo sin reposición
  
### Prueba de permutaciones para dos muestras independientes

```{r}
# Script 12.17: pruebas de permutaciones para variables numéricas.

library(ggpubr)

# Definir las muestras iniciales
a <- c(5.4, 4.7, 6.3, 2.9, 5.9, 5.1, 2.1, 6.2, 1.6, 6.7, 3.0, 3.3,
       5.0, 4.1, 3.3, 3.4, 1.2, 3.8, 5.8, 4.2)
b <- c(4.0, 4.1, 4.3, 4.3, 4.3, 4.2, 4.3, 4.3, 4.4, 4.1, 4.3, 4.0)

# Establecer semilla y cantidad de repeticiones
R = 5999
set.seed(432)


# Función para obtener una permutación.
# Argumentos:
# - i: iterador (para llamadas posteriores).
# - muestra_1, muestra_2: muestras.
# Valor:
# - una lista con las muestras resultantes tras la permutación.
obtener_permutacion <- function(i, muestra_1, muestra_2) {
  n_1 <- length(muestra_1)
  combinada <- c(muestra_1, muestra_2)
  n <- length(combinada)
  permutacion <- sample(combinada, n, replace = FALSE)
  nueva_1 <- permutacion[1:n_1]
  nueva_2 <- permutacion[(n_1+1):n]

  return(list(nueva_1, nueva_2))
}

# Función para calcular la diferencia de un estadístico de interés entre las
# dos muestras.
# Argumentos:
# - muestras: lista con las muestras.
# - FUN: nombre de la función que calcula el estadístico de interés.
# Valor:
# - diferencia de un estadístico para dos muestras.
calcular_diferencia <- function(muestras, FUN) {
  muestra_1 <- muestras[[1]]
  muestra_2 <- muestras[[2]]
  diferencia <- FUN(muestra_1) - FUN(muestra_2)

  return(diferencia)
}

# Función para calcular el valor p.
# Argumentos:
# - distribucion: distribución nula del estadístico de interés.
# - valor_observado: valor del estadístico de interés para las muestras
#   originales.
# - repeticiones: cantidad de permutaciones a realizar.
# - alternative: tipo de hipótesis alternativa. "two.sided" para
#   hipótesis bilateral, "greater" o "less" para hipótesis unilaterales.
# Valor:
# - el valor p calculado.
calcular_valor_p <- function(distribucion, valor_observado,
                             repeticiones, alternative) {
  if(alternative == "two.sided") {
    numerador <- sum(abs(distribucion) > abs(valor_observado)) + 1
    denominador <- repeticiones + 1
    valor_p <- numerador / denominador
  } else if (alternative == "greater") {
    numerador <- sum(distribucion > valor_observado) + 1
    denominador <- repeticiones + 1
    valor_p <- numerador / denominador
  } else { # "less"
    numerador <- sum(distribucion < valor_observado) + 1
    denominador <- repeticiones + 1
    valor_p <- numerador / denominador
  }

  return(valor_p)
}

# Función para graficar una distribución.
# Argumentos:
# - distribucion: distribución nula del estadístico de interés.
# - ...: otros argumentos a ser entregados a gghistogram y ggqqplot.
graficar_distribucion <- function(distribucion, ...) {
  observaciones <- data.frame(distribucion)

  histograma <- gghistogram(observaciones, x = "distribucion",
                            xlab = "Estadístico de interés",
                            ylab = "Frecuencia", bins = 30, ...)
  qq <- ggqqplot(observaciones, x = "distribucion", ...)

  # Crear una única figura con todos los gráficos de dispersión.
  figura <- ggarrange(histograma, qq, ncol = 2, nrow = 1)
  print(figura)
}

# Función para hacer la prueba de permutaciones.
# Argumentos:
# - muestra_1, muestra_2: vectores numéricos con las muestras a comparar.
# - repeticiones: cantidad de permutaciones a realizar.
# - FUN: función del estadístico E para el que se calcula la diferencia.
# - alternative: tipo de hipótesis alternativa. "two.sided" para
#   hipótesis bilateral, "greater" o "less" para hipótesis unilaterales.
# - plot: si es TRUE, construye el gráfico de la distribución generada.
# - ...: otros argumentos a ser entregados a graficar_distribucion.
contrastar_hipotesis_permutaciones <- function(muestra_1, muestra_2,
                                             repeticiones, FUN,
                                             alternative, plot, ...) {

  cat("Prueba de permutaciones\n\n")
  cat("Hipótesis alternativa:", alternative, "\n")
  observado <- calcular_diferencia(list(muestra_1, muestra_2), FUN)
  cat("Valor observado:", observado, "\n")

  # Generar permutaciones
  n_1 <- length(muestra_1)
  permutaciones <- lapply(1:repeticiones, obtener_permutacion,
                          muestra_1,
                          muestra_2)

  # Generar la distribución
  distribucion <- sapply(permutaciones, calcular_diferencia, FUN)

  # Graficar la distribución
  if(plot) {
    graficar_distribucion(distribucion, ...)
  }

  # Calcular y mostrar el valor p
  valor_p <- calcular_valor_p(distribucion, observado, repeticiones,
                              alternative)
  cat("Valor p:", valor_p, "\n\n")
}

# --- Bloque principal ----

# Hacer pruebas de permutaciones para la media y la varianza
contrastar_hipotesis_permutaciones(a, b, repeticiones = R, FUN = mean,
                                   alternative = "two.sided", plot = TRUE,
                                   color = "blue", fill = "blue")
contrastar_hipotesis_permutaciones(a, b, repeticiones = R, FUN = var,
                                   alternative = "two.sided", plot = FALSE)
```

### Prueba de permutaciones para comparar más de dos muestras correlacionadas

verificar la condición de normalidad en las muestras, si no se cumple, se puede usar la prueba de permutaciones.

```{r}
# Script 12.18: prueba de permutaciones para muestras correlacionadas.

library(ez)
library(ggpubr)
library(tidyr)

# Crear la matriz de datos
Algoritmos <- c("Quicksort", "Bubblesort", "Mergesort")
Quicksort <- c(11.2, 22.6, 23.4, 23.3, 21.8, 40.1)
Bubblesort <- c(15.7, 29.3, 30.7, 30.8, 29.8, 50.3)
Mergesort <- c(12.0, 25.7, 25.7, 23.7, 25.5, 44.7)
Instancia <- factor(1:6)

datos_anchos <- data.frame(Instancia, Quicksort, Bubblesort, Mergesort)

datos_largos <- datos_anchos |>
  pivot_longer(all_of(Algoritmos),
               names_to = "Algoritmo",
               values_to = "Tiempo")

datos_largos[["Algoritmo"]] <- factor(datos_largos[["Algoritmo"]],
                                      levels = Algoritmos)

# Verificar la condición de normalidad
g <- ggqqplot(datos_largos, "Tiempo", facet.by = "Algoritmo",
              color = "Algoritmo")
print(g)

# Establecer nivel de significancia
Alfa <- 0.01

# Obtener el valor observado, correspondiente al estadístico F entregado
# por ANOVA para la muestra original.
anova <- ezANOVA(datos_largos, dv = Tiempo, within = Algoritmo,
                 wid = Instancia)
valor_observado <- anova[["ANOVA"]][["F"]]

# Función para obtener una permutación:
# Devuelve una matriz de datos con formato ancho.
obtener_permutacion <- function(i, df_ancho) {
  df_ancho[, 2:4] <- t(apply(df_ancho[, 2:4], 1, sample))
  return(df_ancho)
}

# Obtiene permutaciones
R = 2999
set.seed(432)

permutaciones <- lapply(1:R, obtener_permutacion, datos_anchos)

# Función para obtener el estadístico F para una matriz de datos con
# formato ancho.
obtiene_F <- function(df_ancho) {
  df_largo <- df_ancho |>
    pivot_longer(c("Quicksort", "Bubblesort", "Mergesort"),
                 names_to = "Algoritmo",
                 values_to = "Tiempo")
  df_largo[["Algoritmo"]] <- factor(df_largo[["Algoritmo"]])
  anova <- ezANOVA(df_largo, dv = Tiempo, within = Algoritmo,
                   wid = Instancia)
  return(anova[["ANOVA"]][["F"]])
}

# Genera distribución de estadísticos F con las permutaciones
distribucion <- sapply(permutaciones, obtiene_F)

# Obtener y mostrar el valor p
p <- (sum(distribucion > valor_observado) + 1) / (R + 1)
cat("ANOVA de una vía para muestras pareadas con permutaciones:\n")
cat("Valor p omnibus:", p, "\n")

# Análisis post-hoc

# Función para calcular la media de las diferencias para dos columnas de una
# matriz de datos en formato ancho.
obtiene_media_difs <- function(df_ancho, columna_1, columna_2) {
  media <- mean(df_ancho[[columna_1]] - df_ancho[[columna_2]])
  return(media)
}

# Obtiene las medias de las diferencias observadas
dif_obs_Q_B <- obtiene_media_difs(datos_anchos, "Quicksort", "Bubblesort")
dif_obs_Q_M <- obtiene_media_difs(datos_anchos, "Quicksort", "Mergesort")
dif_obs_B_M <- obtiene_media_difs(datos_anchos, "Bubblesort", "Mergesort")

# Obtiene las distribuciones de las medias de las diferencias permutadas
dist_medias_difs_Q_B <- sapply(permutaciones, obtiene_media_difs,
                               "Quicksort", "Bubblesort")
dist_medias_difs_Q_M <- sapply(permutaciones, obtiene_media_difs,
                               "Quicksort", "Mergesort")
dist_medias_difs_B_M <- sapply(permutaciones, obtiene_media_difs,
                               "Bubblesort", "Mergesort")

# Obtener valores p
num <- sum(abs(dist_medias_difs_Q_B) > abs(dif_obs_Q_B)) + 1
den <- R + 1
p_Q_B <- num / den

num <- sum(abs(dist_medias_difs_Q_M) > abs(dif_obs_Q_M)) + 1
den <- R + 1
p_Q_M <- num / den

num <- sum(abs(dist_medias_difs_B_M) > abs(dif_obs_B_M)) + 1
den <- R + 1
p_B_M <- num / den

valores_p <- c(p_Q_B, p_Q_M, p_B_M)

# Ajustar y mostrar valores p
valores_p_adj <- p.adjust(valores_p, method = "BH")

cat("\nAnálisis post-hoc (permutaciones) para la diferencia de las medias\n")
cat("-------------------------------------------------------------------\n")

cat("Valores p ajustados:\n")
cat(sprintf("Quicksort - Bubblesort: %6.3f\n", valores_p_adj[1]))
cat(sprintf("Quicksort - Mergesort: %6.3f\n", valores_p_adj[2]))
cat(sprintf("Bubblesort - Mergesort: %6.3f\n", valores_p_adj[3]))

cat("\nDiferencias observadas:\n")
cat(sprintf("Quicksort - Bubblesort: %6.3f\n", dif_obs_Q_B))
cat(sprintf("Quicksort - Mergesort: %6.3f\n", dif_obs_Q_M))
cat(sprintf("Bubblesort - Mergesort: %6.3f\n", dif_obs_B_M))
```

