---
title: "lectura09"
author: "Vicente Rojas"
date: "2025-06-29"
output: html_document
---

Lectura 09 : Inferencia y modelos estadisticos

Temario :

1) Modelos Robustos (alternativas a t-student):


  1.1) Robusta a la media usando funcion winmean()

  1.2) Prueba de Yuen usando la funcion yuen()(Para 2 muestras independientes)

  1.3) Prueba de Yuen usando la funcion yuend()(Para 2 muestras pareadas)

  1.4) Analisis robusto de una via para muestras correlacionadas usando la funcion rmanova() y rmmcp()


2) Remuestreo


  2.1) Bootstrap 1 muestra usando funcion boot() y boot.ci()

  2.2) Bootstrap 2 muestras independientes usando la funcion two.boot()

  2.3) Bootstrap 2 muestras apareadas usando la funcion bootES()

  2.4) Permutacion 2 muestras independientes usando funciones que definen la permutacion

  2.5) Permutaciones para mas de 2 muestras correlacionadas usando ezAnova()



1.1) Robusta a la media usando funcion winmean()

Se analiza la mediana truncada es decir la media de los datos con un porcentaje de datos extremos eliminados.
Se escoge un gamma entre 0 y 1, donde gamma = 0.2 significa que se eliminan el 20% de los datos extremos.

```{r}
library(WRS2)
x <- c(2, 3, 4, 5, 100)

mean(x)  # Resultado: 22.8
winmean(x, tr = 0.2)  # Resultado: 4.8

```
1.2) Prueba de Yuen usando la funcion yuen()(Para 2 muestras independientes)

Se utiliza cuando las muestras no cumplen con la normalidad, es una alternativa a la t-student.

Para que se apliquen se debe cumplir las siguientes condiciones:
  
  Las observaciones en una muestra son independientes, esto significa que la elección de una observación no influye en la selección de otra para esa   muestra. 
  
  Las muestras son independientes, es decir que las observaciones de una muestra no están relacionadas con ninguna de las observaciones de la otra.    
  La(s) variable(s) estudiada(s) tiene(n) al menos escala de intervalos iguales


Ejemplo para muestras a y b
```{r}
library(ggpubr) 
library(WRS2) 
# Construir la matriz de datos  
a <-c(25.1, 25.2, 25.3, 25.3, 25.4, 25.4, 25.5, 25.5, 25.6, 25.8, 25.8, 25.9, 25.9, 26.0, 26.0, 26.2, 26.2, 26.2, 26.3, 26.4, 26.5, 26.5, 26.6, 26.7, 26.7, 26.9, 26.9, 27.0, 27.1, 27.3, 27.8, 28.4, 28.5, 29.0, 29.8, 30.2, 31.8, 31.9, 33.3, 33.7) 
b <-c(24.1, 24.4, 24.4, 24.5, 24.7, 24.8, 24.8, 25.1, 25.2, 25.2, 25.2, 25.3, 25.4, 25.7, 25.7, 26.3, 26.3, 26.4, 26.5, 27.2, 27.7, 28.3, 28.4, 28.4, 28.6, 28.7, 29.6, 29.9, 30.1, 30.5)
Tiempo <-c(a, b)
Algoritmo <-c(rep("A", length(a)), rep("B", length(b))) 
datos <-data.frame(Tiempo, Algoritmo) 
# Comprobar normalidad 
qq <-ggqqplot(datos, x = "Tiempo", facet.by = "Algoritmo", 
              palette = c("steelblue", "steelblue1"), color = "Algoritmo",
              xlab = "Cuantil teórico", ylab = "Tiempo de ejecución [ms]")

qq <-qq + theme(legend.position = "none")
print(qq)

```


```{r}
# Aplicar una poda del 20% a las muestras 
gamma <- 0.2 
n_a <- length(a) 
n_b <- length(b) 
poda_a <- floor(n_a * gamma) 
poda_b <- floor(n_b * gamma) 
a_trunc <- a[poda_a:(n_a- poda_a)] 
b_trunc <- b[poda_b:(n_b- poda_b)] 
Tiempo_t <- c(a_trunc, b_trunc) 
Algoritmo_t <- c(rep("A", length(a_trunc)), rep("B", length(b_trunc))) 
datos_t <- data.frame(Tiempo_t, Algoritmo_t) 
qq_t <- ggqqplot(datos_t, x = "Tiempo_t", facet.by = "Algoritmo_t",
                 palette = c("steelblue", "steelblue1"), color = "Algoritmo_t", 
                 xlab = "Cuantil teórico", ylab = "Tiempo de ejecución truncado [ms]")
qq_t <- qq_t + theme(legend.position = "none")
print(qq_t)

```

```{r}
# Aplicar y mostrar la prueba de Yuen asintótica
prueba <- yuen(Tiempo ~ Algoritmo, data = datos, tr = gamma) 
cat("\nPrueba de Yuen para dos muestras independientes\n") 
cat("-----------------------------------------------\n") 
print(prueba) 
# Establecer cantidad de repeticiones con bootstrapping 
B <- 999 
# Aplicar la prueba de Yuen con bootstrapping y la media 
set.seed(135) 
prueba_media <- pb2gen(Tiempo ~ Algoritmo, data=datos, est="mean", nboot=B) 
# Aplicar la prueba de Yuen con bootstrapping y la mediana 
set.seed(135)
prueba_mediana <- pb2gen(Tiempo ~ Algoritmo, data=datos, est="median", nboot=B) 
# Mostrar los resultados 64 cat("\nPrueba de Yuen- implemetación con bootstrapping\n") 
cat("================================================\n") 
cat("\nResultado al usar bootstrapping y la media como estimador\n") 
cat("---------------------------------------------------------\n") 
print(prueba_media) 
cat("\nResultado al usar bootstrapping y la mediana como estimador\n") 
cat("-----------------------------------------------------------\n") 
print(prueba_mediana)
```

donde la funcion pb2gen() es una implementacion de la prueba de Yuen con bootstrapping, donde se puede elegir entre la media o la mediana como estimador.


1.3) Prueba de Yuen usando la funcion yuend()(Para 2 muestras pareadas)


La prueba de Yuen pareada es una alternativa robusta a la prueba t de Student pareada. Se utiliza cuando los datos no cumplen con la normalidad, tienen asimetría o presentan valores atípicos. Trabaja con la media truncada de las diferencias entre pares.

Supuestos:

  Los pares de observaciones son independientes entre sí.

  La variable medida está en escala de intervalos iguales.

  Las diferencias entre pares deben tener una distribución aproximadamente simétrica.

  Se recomienda no usar podas demasiado cercanas al 50% (la mediana) y contar con al menos 10–15 pares tras la poda.

Hipótesis:

  H0: La media truncada de las diferencias es igual a 0.

  Ha: La media truncada de las diferencias es distinta de 0.

```{r}
library(ggpubr) 
library(WRS2) 

# Construir las estructuras con los datos observados 
a <-c(32.3, 32.0, 32.0, 36.0, 34.2, 32.7, 32.5, 32.0, 32.1, 33.4, 32.3, 37.2, 32.1, 32.0, 33.9, 34.1, 36.6, 34.5, 32.7, 33.1, 32.7, 32.1, 36.7, 32.2, 38.0) 
b <-c(35.3, 20.1, 18.6, 46.3, 42.1, 39.3, 37.0, 28.0, 30.2, 40.4, 35.6, 50.7, 33.6, 17.9, 41.0, 41.6, 47.8, 43.2, 38.3, 39.9, 38.0, 28.3, 48.4, 34.7, 52.9) 
dif <- a-b 

# Aplicar una poda del 20% al conjunto de diferencias 
gamma <-0.2 
n <-length(dif) 
poda <-floor(n * gamma) 
dif <-sort(dif) 
dif_trunc <-dif[(poda + 1):(n- poda)] 
n_t <-length(dif_trunc)

# Obtener gráficos Q-Q de las diferencias originales y podadas 
datos <-data.frame(Diferencia = c(dif, dif_trunc), 
                   Muestra = c(rep("Original", n),rep("Podados", n_t))) 
qq <-ggqqplot(datos, x = "Diferencia", facet.by = "Muestra",
              palette = c("steelblue", "steelblue1"), color = "Muestra", 
              xlab = "Cuantil teórico", 
              ylab = "Diferencias en tiempos\nde ejecución [ms]") 
qq <-qq + theme(legend.position = "none") 
print(qq)

```
Aplica la prueba de Yuen pareada a las diferencias truncadas:

```{r}
# Aplicar y mostrar la prueba de Yuen para muestras apareadas 
gamma <- 0.2 
prueba <- yuend(x = a, y = b, tr = gamma) 
cat("Prueba de Yuen para dos muestras pareadas\n") 
cat("-----------------------------------------\n") 
print(prueba)

```



1.4) Análisis robusto de una vía para muestras independientes usando la función rmanova() y rmmcp()

Uasando parte de la funcion anova de una vía para muestras independientes que podemos usar cuando los tamaños muestrales son muy diferentes o no se cumple la condición de homocedasticidad.

La función t1way(formula, data, tr, alpha) efectúa un procedimiento similar a ANOVA usando medias truncadas. A su vez, la función lincon(formula, data, tr, alpha) permite realizar el procedimiento posthoc correspondiente. o mcppb20(formula, data, tr, nboot).

```{r}
library(ggpubr)
library(WRS2) 
# Construir las estructuras con los datos 
A <- c(25.1, 25.2, 25.3, 25.3, 25.4, 25.4, 25.5, 25.5, 25.6, 25.8, 25.8, 25.9, 25.9, 26.0, 26.0, 26.2, 26.2, 26.2, 26.3, 26.4, 26.5, 26.5, 26.6, 26.7, 26.7, 26.9, 26.9, 27.0, 27.1, 27.3, 27.8, 28.4, 28.5, 29.0, 29.8, 30.2, 31.8, 31.9, 33.3, 33.7) 
B <- c(24.1, 24.4, 24.4, 24.5, 24.7, 24.8, 24.8, 25.1, 25.2, 25.2, 25.2, 25.3, 25.4, 25.7, 25.7, 26.3, 26.3, 26.4, 26.5, 27.2, 27.7, 28.3, 28.4, 28.4, 28.6, 28.7, 29.6, 29.9, 30.1, 30.5) 
C <-c(24.5, 24.5, 24.5, 24.5, 24.5, 24.5, 24.6, 24.6, 24.6, 24.6, 24.6, 24.6, 24.7, 24.7, 24.7, 24.7, 24.8, 25.0, 25.0, 25.0, 25.2, 25.2, 25.2, 25.2, 25.5, 25.7, 25.9, 26.2, 26.5, 26.5, 26.7, 27.0, 29.2, 29.9, 30.1) 
Tiempo <-c(A, B, C) 
Algoritmo <-c(rep("A", length(A)), rep("B", length(B)), rep("C", length(C))) 
Algoritmo <-factor(Algoritmo) 
datos <-data.frame(Tiempo, Algoritmo)
# Obtener gráficos Q-Q de las muestras 
qq <-ggqqplot(datos, x = "Tiempo", facet.by = "Algoritmo", color = "Algoritmo", 
              palette = c("steelblue", "steelblue1", "steelblue4"), 
              xlab = "Cuantil teórico", ylab = "Tiempos\nde ejecución [ms]") 
qq <-qq + theme(legend.position = "none") 
print(qq)
```



De esta forma, podemos aplicar el análisis robusto de una vía para muestras independientes, con las siguientes hipótesis:
H0: el tiempo de ejecución promedio necesario para resolver instancias de igual tamaño es el mismo para los tres algoritmos. 
  Matemáticamente: µA = µB = µC.

HA: el tiempo de ejecución promedio necesario para resolver instancias de igual tamaño es diferente para al menos un algoritmo.
  Matemáticamente: ∃i,j∈{A,B,C}, i≠j | µi ≠ µj.

```{r}
# Fijar nivel de significación, nivel de poda y nro. de iteraciones bootstrap 
alfa <-0.05
gamma <-0.2 
nboot <-999 
# Comparar los diferentes algoritmos usando medias truncadas 
set.seed(666) 
una_via <-t1way(Tiempo ~ Algoritmo, data = datos, 
                tr = gamma, alpha = alfa, nboot = nboot)
cat("Análisis de una vía para muestras independientes (asimpótico)\n")
cat("-------------------------------------------------------------\n") 
print(una_via) 
if(una_via[["p.value"]] < alfa) { 
  una_via_ph <-lincon(Tiempo ~ Algoritmo, data = datos, 
                      tr = gamma, alpha = alfa)
                                                                                                                                                                                                                                                                                          
cat("Análisis post-hoc para muestras independientes (asimpótico)\n")
cat("-----------------------------------------------------------\n") 
print(una_via_ph)
}
```

REMUESTREO

La idea básica detrás del remuestreo es extraer repetidamente muestras desde un conjunto original de datos observados para obtener información sobre la población de la que provienen. A estas muestras de la muestra original se les conoce como remuestras.

Bootstraping

El bootstraping es una técnica de remuestreo que permite estimar la distribución de una estadística a partir de una muestra. Se basa en la idea de tomar múltiples muestras con reemplazo de los datos originales para crear una distribución empírica de la estadística de interés.

2.1) Bootstrap 1 muestra usando función boot() y boot.ci()


```{r}
library(boot)
library(bootES)
# Crear muestra inicial, mostrar su histograma y calcular la media
muestra <- c(79, 75, 84, 75, 94, 82, 76, 90, 79, 88)
# Establecer cantidad de remuestreos y nivel de significación
B <- 2000
alfa <- 0.01

# Función para calcular el estadístico: media de la remuestra
media <- function(valores, i) {
  mean(valores[i])
}
# Construir la distribución bootstrap usando el paquete boot
set.seed(432)
distribucion_b <- boot(muestra, statistic = media, R = B)
# Mostrar y graficar la distribución bootstrap
print(distribucion_b)
plot(distribucion_b)
# Construir y mostrar los intervalos de confianza
ics <- boot.ci(distribucion_b, conf = 1 - alfa,
                type = c("norm", "perc", "bca"))
cat("\n\n")
print(ics)

# Imprimir los intervalos de confianza y la media de la muestra
cat("\n\nIntervalos de confianza para la media de la muestra:\n")
cat("--------------------------------------------------\n")
cat("Intervalo de confianza normal: ", ics$normal[2], "-", ics$normal[3], "\n")
cat("Intervalo de confianza percentil: ", ics$percent[4], "-", ics$percent[5], "\n")
cat("Intervalo de confianza BCa: ", ics$bca[4], "-", ics$bca[5], "\n")
# Imprimir la media de la muestra
cat("Media de la muestra: ", mean(muestra), "\n")

#imprimir la desviación estándar de bootstrap
cat("Desviación estándar de bootstrap: ", sd(distribucion_b$t), "\n")
#imprimir el error estándar de bootstrap
cat("Error estándar de bootstrap: ", sd(distribucion_b$t) / sqrt(length(muestra)), "\n")
#imprmir media bootstrap
cat("Media bootstrap: ", mean(distribucion_b$t), "\n")
#imprimir el valor que mas se repite y su frecuencia
cat("Valor más frecuente en bootstrap: ", names(which.max(table(distribucion_b$t))), "\n")
cat("Frecuencia del valor más frecuente en bootstrap: ", max(table(distribucion_b$t)), "\n")

```


Usando la función bootES() para calcular el bootstrap 

La función bootES() del paquete bootES es una alternativa a la función boot() que permite calcular intervalos de confianza y graficar la distribución bootstrap de manera más sencilla.
Ya que implementa la media, mediana y otros estadísticos de interés. y no requiere definir una función estadística personalizada.


```{r}
#Construir la distribución bootstrap usando el paquete bootES
# (esta llamada además calcula (solo) un intervalo de confianza
# y grafica la distribución bootstrap).
set.seed(432)
distribucion_bES <- bootES(muestra, R = B, ci.type = "bca",
                           ci.conf = 1 - alfa, plot = TRUE)
# Mostrar bootstrap obtenida con bootES
print(distribucion_bES)
```


ahora definimos las siguientes hipotesis, 
h0 : la media de la muestra es igual a 75
ha : la media de la muestra es mayor a 75

con este constraste de hipotesis basada en la distribucion normal centrada en el valor nulo para a partir de ella obtener el valor p

p = (r+1)/(B+1)
r: número de remuestras con media mayor o igual al valor nulo (75 en este caso).
B: número total de remuestras (2000 en este caso).

```{r}
#Desplazar la distribución bootstrap para que se centre en el valor nulo
valor_nulo <- 75
desplazamiento <- mean(distribucion_b[["t"]]) - valor_nulo
distribucion_nula <- distribucion_b[["t"]] - desplazamiento
# Determinar y mostrar la media observada y el valor p
valor_observado <- media(muestra, 1:length(muestra))
p <- (sum(distribucion_nula > valor_observado) + 1) / (B + 1)
cat("Media observada:", valor_observado, "\n")
cat("Valor p:", p, "\n")

```
rechazamos la hipotesis nula ya que el valor p es menor que 0.01, por lo tanto la media de la muestra es significativamente mayor a 75.
con un nivel de significación de 0.01. es decir un nivel de confianza del 99%.





2.2) Bootstrap 2 muestras independientes usando la función two.boot()

El proceso a seguir es :

1. Fijar la cantidad B de repeticiones bootstrap. 
2. En cada repetición: 
  a) hacer un remuestreo con reposición de tamaño nA a partir de la muestra A 
  b) hacer un remuestreo con reposición de tamaño nB a partir de la muestra B. 
  c) calcular el estadístico de interés con las remuestras conseguidas 
3. Construir el intervalo de confianza para el estadístico de interés a partir de la distribución bootstrap generada.

Usando el paquete two.boot() para calcular el bootstrap de dos muestras independientes:



Ademas planteamos las siguientes hipotesis:
Ho: La diferencia entre las medias de las dos muestras es igual a -0.5
Ha: La diferencia entre las medias de las dos muestras es mayor a -0.5


```{r}
library(boot)
library(ggpubr)
library(simpleboot)

# Definir las muestras obtenidas
hombres <- c(1.3, 1.5, 1.6, 1.7, 1.7, 1.9, 2.3, 2.4, 2.6, 2.6, 2.7, 2.8, 3.2, 3.7,4.1, 4.4, 4.5, 4.8, 5.2, 5.2, 5.3, 5.5, 5.5, 5.6, 5.6, 5.7, 5.7)
mujeres <- c(3.5, 3.6, 3.8, 4.3, 4.5, 4.5, 4.9, 5.1, 5.3, 5.3, 5.5, 5.8, 6.0, 6.3, 6.3, 6.4, 6.4, 6.6, 6.7)
n_hombres <- length(hombres)
n_mujeres <- length(mujeres)

# Comprobar la normalidad de las muestras
print(shapiro.test(hombres))
print(shapiro.test(mujeres))

# Calcular y mostrar la diferencia observada entre las medias muestrales
media_hombres <- mean(hombres)
media_mujeres <- mean(mujeres)
diferencia_obs <- media_hombres - media_mujeres

cat("Media hombres:", round(media_hombres, 3), "\n")
cat("Media mujeres:", round(media_mujeres, 3), "\n")
cat("Diferencia observada:", round(diferencia_obs, 3), "\n\n")

# Crear la distribución bootstrap
B <- 9999
set.seed(432)
distribucion_b <- two.boot(hombres, mujeres, FUN = mean, R = B)
# Examinar la distribución bootstrap
datos <- data.frame(diferencias = distribucion_b[["t"]])
g_hist <- gghistogram(datos, x = "diferencias", bins = 100,
                      xlab = "Diferencia de medias", ylab = "Frecuencia")
g_qq <- ggqqplot(datos, x = "diferencias")
g <- ggarrange(g_hist, g_qq)
print(g)
media_b <- mean(datos[["diferencias"]])
sd_b <- sd(datos[["diferencias"]])
cat("Distribución bootstrap:\n")
cat("\tMedia:", round(media_b, 3), "\n")
cat("\tDesviación estándar:", round(sd_b, 3), "\n\n")

# Construir y mostrar los intervalos de confianza
alfa <- 0.05
intervalo_bca <- boot.ci(distribucion_b, conf = 1 - alfa, type = "bca")
print(intervalo_bca)

# Desplazar la distribución bootstrap para reflejar la hipótesis nula
valor_nulo <- -0.5
desplazamiento <- media_b - valor_nulo
distribucion_nula <- datos[["diferencias"]] - desplazamiento

# Determinar y mostrar el valor p
p <- (sum(distribucion_nula < diferencia_obs) + 1) / (B + 1)
cat("\nValor p:", p, "\n")

```


dado a que valor p es menor que 0.05, rechazamos la hipótesis nula, lo que indica que la diferencia entre las medias de las dos muestras es significativamente mayor a -0.5 con un nivel de confianza del 95%.

2.3) Bootstrap 2 muestras apareadas usando la función bootES()

Las muestra apareadas son aquellas donde cada observación de una muestra está relacionada con una observación de otra muestra. Por ejemplo, en un estudio donde se mide el rendimiento de un grupo de estudiantes antes y después de un curso, cada estudiante tiene dos mediciones: una antes del curso y otra después.

Es decir las muestras son tomadas al mismo grupo de individuos en dos momentos diferentes o bajo dos condiciones diferentes.

Para este ejercicio se propone las siguiente hipótesis:

h0: las diferencias entre las calificaiones de los estudiantes antes y después del curso son iguales a 0,5

ha: las diferencias entre las calificaciones de los estudiantes antes y después del curso son diferentes a 0,5

```{r}
library(bootES)
set.seed(432)

# Ingresar datos originales.
prueba_1 <- c(3.5, 2.7, 1.0, 1.8, 1.6, 4.3, 5.8, 6.4, 3.9, 4.3, 3.4,
              5.3, 5.8, 5.3, 2.0, 1.3, 4.0, 5.3, 1.6, 3.6)
prueba_2 <- c(5.2, 5.1, 5.9, 4.8, 1.4, 2.3, 6.8, 5.3, 3.1, 3.8, 4.6,
              1.2, 3.9, 2.0, 1.7, 3.3, 6.0, 4.8, 6.9, 1.3)

# Calcular la diferencia entre ambas observaciones.
diferencia <- prueba_2 - prueba_1
# Calcular la media observada de las diferencias.
valor_observado <- mean(diferencia)
# Generar la distribución bootstrap y su intervalo de confianza.
B <- 3999
alfa <- 0.05
distribucion_bES <- bootES(diferencia, R = B, ci.type = "bca",
                           ci.conf = 1 - alfa, plot = FALSE)

# Desplazar la distribución bootstrap para reflejar la hipótesis nula.
valor_nulo <- 0.5
desplazamiento <- mean(distribucion_bES[["t"]]) - valor_nulo
distribucion_nula <- distribucion_bES[["t"]] - desplazamiento

# Determinar el valor p.
p <- (sum(abs(distribucion_nula) > abs(valor_observado)) + 1) / (B + 1)

# Mostrar los resultados
cat("Media de las diferencia observada:", round(valor_observado, 3), "\n\n")
cat("Distribución bootstrap e intervalo de confianza:\n")
print(distribucion_bES)
cat("Valor p:", round(p, 3), "\n")
```

Dado a que el valor p es mayor que 0.05, no rechazamos la hipótesis nula, lo que indica que las diferencias entre las calificaciones de los estudiantes antes y después del curso no son significativamente diferentes a 0.5 con un nivel de confianza del 95%.


2.4) Permutación 2 muestras independientes usando funciones que definen la permutación

La prueba de permutación es una técnica estadística que permite evaluar la significancia de la diferencia entre dos grupos sin asumir una distribución específica. Se basa en la idea de comparar la diferencia observada entre las medias de los grupos con las diferencias obtenidas al permutar los datos.

En comparación con el bootstrap, la prueba de permutación no requiere remuestreo con reemplazo, sino que utiliza todas las observaciones disponibles para generar nuevas distribuciones de la estadística de interés.


En términos generales, las pruebas exactas de permutaciones para la diferencia entre dos grupos A y B de tamaños nA y nB, respectivamente, sigue los siguientes pasos: 
1. Calcular la diferencia entre el estadístico de interés observado para ambos grupos. 
2. Juntar ambas muestras en una muestra combinada. 
3. Obtener todas las formas de separar la muestra combinada en dos grupos de tamaños nA y nB. 
4. Construir la distribución de las diferencias entre el estadístico de interés obtenido para ambos grupos en cada una de las permutaciones. 
5. Calcular el valor p exacto, dado por la proporción de permutaciones en que el valor (absoluto, si es bilateral) de la diferencia calculada es menor/mayor o igual al valor (absoluto si es bilateral) de la diferencia observada.


El ejemplo de dos grupos de ingenieros y no ingenieros, que se comparan sus calificaciones en sus calificaciones en la universidad.

Ahora se propene las siguientes hipótesis:
h0: La diferencia entre las medias de las calificaciones de ingenieros y no ingenieros es igual a 0.
ha: La diferencia entre las medias de las calificaciones de ingenieros y no ingenieros es diferente a 0.


tambien si propone otro estudio con respecto a la varianza de las calificaciones de ingenieros y no ingenieros, donde se propone las siguientes hipótesis:

h0: La varianza entre las calificaciones entre los ingenieros y no ingenieros es igual a 0.
ha: La varianza entre las calificaciones entre los ingenieros y no ingenieros es diferente a 0.

```{r}

library(ggpubr)

# Definir las muestras iniciales
a <- c(5.4, 4.7, 6.3, 2.9, 5.9, 5.1, 2.1, 6.2, 1.6, 6.7, 3.0, 3.3,
        5.0, 4.1, 3.3, 3.4, 1.2, 3.8, 5.8, 4.2)
b <- c(4.0, 4.1, 4.3, 4.3, 4.3, 4.2, 4.3, 4.3, 4.4, 4.1, 4.3, 4.0)

# Establecer semilla y cantidad de repeticiones
R = 5999
set.seed(432)

# Función para obtener una permutación.
# Argumentos:
# -i: iterador (para llamadas posteriores).
# -muestra_1, muestra_2: muestras.
# Valor:
# -lista con las muestras resultantes tras la permutación.
obtiene_permutacion <- function(i, muestra_1, muestra_2) {
  n_1 <- length(muestra_1)
  combinada <- c(muestra_1, muestra_2)
  n <- length(combinada)
  permutacion <- sample(combinada, n, replace = FALSE)
  nueva_1 <- permutacion[1:n_1]
  nueva_2 <- permutacion[(n_1 + 1):n]
  
  return(list(nueva_1, nueva_2))
}

# Función para calcular la diferencia de un estadístico de interés entre las
# dos muestras.
# Argumentos:
# -muestras: lista con las muestras.
# -FUN: nombre de la función que calcula el estadístico de interés.
# Valor:
# -diferencia de un estadístico para dos muestras.
calcular_diferencia <- function(muestras, FUN) {
  muestra_1 <- muestras[[1]]
  muestra_2 <- muestras[[2]]
  diferencia <- FUN(muestra_1) - FUN(muestra_2)
  
  return(diferencia)
}

# Función para calcular el valor p.
# Argumentos:
# -distribucion: distribución nula del estadístico de interés.
# -valor_observado: valor del estadístico de interés para las muestras
# originales.
# -repeticiones: cantidad de permutaciones a realizar.
# -alternative: tipo de hipótesis alternativa. "two.sided" para
# hipótesis bilateral, "greater" o "less" para hipótesis unilaterales.
# Valor:
# -el valorp calculado.
calcular_valor_p <- function(distribucion, valor_observado,
                             repeticiones, alternative) {
  if (alternative == "two.sided") {
    numerador <- sum(abs(distribucion) > abs(valor_observado)) + 1
    denominador <- repeticiones + 1
    valor_p <- numerador / denominador
  } else if (alternative == "greater") {
    numerador <- sum(distribucion > valor_observado) + 1
    denominador <- repeticiones + 1
    valor_p <- numerador / denominador
  } else {
    numerador <- sum(distribucion < valor_observado) + 1
    denominador <- repeticiones + 1
    valor_p <- numerador / denominador
  }
  
  return(valor_p)
}

# Función para graficar una distribución.
# Argumentos:
# -distribucion: distribución nula del estadístico de interés.
# -...: otros argumentos a ser entregados a gghistogram y ggqqplot.

graficar_distribucion <- function(distribucion, ...) {
  observaciones <- data.frame(distribucion)
  
  histograma <- gghistogram(observaciones, x = "distribucion",
                            xlab = "Estadístico de interés",
                            ylab = "Frecuencia", bins = 30, ...)
  qq <- ggqqplot(observaciones, x = "distribucion", ...)
  
  # Crear una única figura con todos los gráficos de dispersión.
  figura <- ggarrange(histograma, qq, ncol = 2, nrow = 1)
  print(figura)
}

# Función para hacer la prueba de permutaciones.
# Argumentos:
# -muestra_1, muestra_2: vectores numéricos con las muestras a comparar.
# -repeticiones: cantidad de permutaciones a realizar.
# -FUN: función del estadístico E para el que se calcula la diferencia.
# -alternative: tipo de hipótesis alternativa. "two.sided" para
# hipótesis bilateral, "greater" o "less" para hipótesis unilaterales.
# -plot: si es TRUE, construye el gráfico de la distribución generada.
# -...: otros argumentos a ser entregados a graficar_distribucion.

contrastar_hipotesis_permutaciones <- function(muestra_1, muestra_2,
                                                repeticiones, FUN,
                                                alternative, plot, ...) {
  cat("Prueba de permutaciones\n\n")
  cat("Hipótesis alternativa:", alternative, "\n")
  observado <- calcular_diferencia(list(muestra_1, muestra_2), FUN)
  cat("Valor observado:", observado, "\n")
  
  # Generar permutaciones
  n_1 <- length(muestra_1)
  permutaciones <- lapply(1:repeticiones, obtiene_permutacion,
                          muestra_1, muestra_2)
  
  # Generar la distribución
  distribucion <- sapply(permutaciones, calcular_diferencia, FUN)
  
  # Graficar la distribución
  if (plot) {
    graficar_distribucion(distribucion, ...)
  }
  
  # Calcular y mostrar el valor p
  valor_p <- calcular_valor_p(distribucion, observado,
                              repeticiones, alternative)
  
  cat("Valor p:", valor_p, "\n\n")
}

# Hacer pruebas de permutaciones para la media y la varianza
contrastar_hipotesis_permutaciones(a, b, repeticiones = R, FUN = mean,
                                    alternative = "two.sided", plot = TRUE,
                                    color = "blue", fill = "blue")
contrastar_hipotesis_permutaciones(a, b, repeticiones = R, FUN = var,
                                    alternative = "two.sided", plot = FALSE)
```


Sobre el primer contraste de hipótesis, dado que el valor p es mayor que 0.05, no rechazamos la hipótesis nula, lo que indica que la diferencia entre las medias de las calificaciones de ingenieros y no ingenieros no es significativamente diferente a 0 con un nivel de confianza del 95%.

Sobre el segundo contraste de hipotesis, se obtine un valor p menor a 0.05, lo que indica que la varianza entre las calificaciones de ingenieros y no ingenieros es significativamente diferente a 0 con un nivel de confianza del 95%.



2.5) Prueba de permutación para dos muestras apareadas usando la función permES()

Ahora las muestras son apareadas, es decir, cada observación de una muestra está relacionada con una observación de otra muestra. Por ejemplo, en un estudio donde se mide el rendimiento de un grupo de estudiantes antes y después de un curso, cada estudiante tiene dos mediciones: una antes del curso y otra después.

El ejemplo consiste en la comparacion de 3 muestras, de la eficiencia de 3 algoritmos de ordenamiento, donde se mide el tiempo de ejecución de cada algoritmo en una serie de instancias.

Se estudian las siguientes hipótesis:

h0: 
- en promedio no hay diferencias en el tiempo de ejecución entre los      algoritmos a , b y c.
- µ(B−Q) = µ(M−Q) = µ(M−B) = 0.

ha:
- en promedio hay diferencias en el tiempo de ejecución entre los algoritmos es dirente, para al menos un par de algoritmos.
- ∃i,j∈{A,B,C}, i≠j | µi ≠ µj.

en el caso de que se rechace la hipótesis nula, se puede realizar un análisis post-hoc para determinar qué pares de algoritmos son significativamente diferentes entre sí.

```{r}
library(ez)
library(ggpubr)
library(tidyr)

# Crear la matriz de datos
Algoritmos <-c("Quicksort", "Bubblesort", "Mergesort")
Quicksort <-c(11.2, 22.6, 23.4, 23.3, 21.8, 40.1)
Bubblesort <-c(15.7, 29.3, 30.7, 30.8, 29.8, 50.3)
Mergesort <-c(12.0, 25.7, 25.7, 23.7, 25.5, 44.7)
Instancia <-factor(1:6)
datos_anchos <-data.frame(Instancia, Quicksort, Bubblesort, Mergesort)

datos_largos <-datos_anchos |>
  pivot_longer(all_of(Algoritmos),
               names_to = "Algoritmo",
               values_to = "Tiempo")
datos_largos[["Algoritmo"]] <-factor(datos_largos[["Algoritmo"]],
                                      levels = Algoritmos)

# Verificar la condición de normalidad
g <-ggqqplot(datos_largos, "Tiempo", facet.by = "Algoritmo",
              color = "Algoritmo")
print(g)

# Establecer nivel de significación
alfa <-0.01

# Obtener el valor observado, correspondiente al estadístico F entregado
# por ANOVA para la muestra original.
anova <-ezANOVA(datos_largos, dv = Tiempo, within = Algoritmo,
                 wid = Instancia)
valor_observado <-anova[["ANOVA"]][["F"]]

# Función para obtener una permutación;
# devuelve una matriz de datos con formato ancho.
obtiene_permutacion <-function(i, df_ancho) {
  df_ancho[, 2:4] <-t(apply(df_ancho[, 2:4], 1, sample))
  return(df_ancho)
}

# Obtiene permutaciones
R = 2999
set.seed(432)
permutaciones <-lapply(1:R, obtiene_permutacion, datos_anchos)

# Función para obtener el estadístico F para una matriz de datos con
# formato ancho.
obtiene_F <-function(df_ancho) {
  df_largo <-df_ancho |>
    pivot_longer(c("Quicksort", "Bubblesort", "Mergesort"),
                 names_to = "Algoritmo",
                 values_to = "Tiempo")
  df_largo[["Algoritmo"]] <-factor(df_largo[["Algoritmo"]])
  
  anova <-ezANOVA(df_largo, dv = Tiempo, within = Algoritmo,
                   wid = Instancia)
  return(anova[["ANOVA"]][["F"]])
}

# Genera distribución de estadísticos F con las permutaciones
distribucion <-sapply(permutaciones, obtiene_F)

# Obtener y mostrar el valor p
p <-(sum(distribucion > valor_observado) + 1) / (R + 1)
cat("ANOVA de una vía para muestras pareadas con permutaciones:\n")
cat("Valor p ómnibus:", p, "\n")

# Análisis post-hoc

# Función para calcular la media de las diferencias para dos columnas de una
# matriz de datos en formato ancho.
obtiene_media_difs <-function(df_ancho, columna_1, columna_2) {
  media <-mean(df_ancho[[columna_1]]- df_ancho[[columna_2]])
  return(media)
}

# Obtiene las las medias de las diferencias observadas
dif_obs_Q_B <-obtiene_media_difs(datos_anchos, "Quicksort", "Bubblesort")
dif_obs_Q_M <-obtiene_media_difs(datos_anchos, "Quicksort", "Mergesort")
dif_obs_B_M <-obtiene_media_difs(datos_anchos, "Bubblesort", "Mergesort")

# Obtiene las distribuciones de las medias de las diferencias permutadas
dist_medias_difs_Q_B <-sapply(permutaciones, obtiene_media_difs,
                               "Quicksort", "Bubblesort")
dist_medias_difs_Q_M <-sapply(permutaciones, obtiene_media_difs,
                               "Quicksort", "Mergesort")
dist_medias_difs_B_M <-sapply(permutaciones, obtiene_media_difs,
                               "Bubblesort", "Mergesort")

# Obtener valores p
num <-sum(abs(dist_medias_difs_Q_B) > abs(dif_obs_Q_B)) + 1
den <-R + 1
p_Q_B <-num / den

num <-sum(abs(dist_medias_difs_Q_M) > abs(dif_obs_Q_M)) + 1
den <-R + 1
p_Q_M <-num / den

num <-sum(abs(dist_medias_difs_B_M) > abs(dif_obs_B_M)) + 1
den <-R + 1
p_B_M <-num / den

valores_p <-c(p_Q_B, p_Q_M, p_B_M)
# Ajustar y mostrar valores p
valores_p_adj <-p.adjust(valores_p, method = "BH")

cat("\n\n")
cat("Análisis post-hoc (permutaciones) para la diferencia de las medias\n")
cat("------------------------------------------------------------------\n")
cat("Valores p ajustados:\n")
cat(sprintf("Quicksort- Bubblesort: %.3f\n", valores_p_adj[1]))
cat(sprintf(" Quicksort- Mergesort: %.3f\n", valores_p_adj[2]))
cat(sprintf("Bubblesort- Mergesort: %.3f\n", valores_p_adj[3]))

cat("\nDiferencias observadas:\n")
cat(sprintf("Quicksort- Bubblesort: %6.3f\n", dif_obs_Q_B))
cat(sprintf(" Quicksort- Mergesort: %6.3f\n", dif_obs_Q_M))
cat(sprintf("Bubblesort- Mergesort: %6.3f\n", dif_obs_B_M))
```


el valor p de la prueba omnibus es menor que 0.01, por lo que rechazamos la hipótesis nula, lo que indica que hay diferencias significativas en el tiempo de ejecución entre al menos un par de algoritmos con un nivel de confianza del 99%.

Ahora se realiza el análisis post-hoc, donde se obtiene los valores p ajustados para las diferencias entre las medias de los pares de algoritmos.
arrojando los siguientes resultados:

Valores p ajustados: 
Quicksort- Bubblesort: 0.001 
Quicksort-Mergesort: 0.266 
Bubblesort- Mergesort: 0.032 

Diferencias observadas: 
Quicksort- Bubblesort:-7.367 
Quicksort-Mergesort:-2.483 
Bubblesort- Mergesort: 4.883

Se concluye que existen diferencias significativas entre 
Quicksort - Bubblesort y Bubblesort - Mergesort, pero no entre Quicksort - Mergesort, con un nivel de confianza del 99%. dado que los valores p ajustados son menores que 0.01 para las primeras dos comparaciones y mayor para la última.

y las diferencias observadas son significativas, ya que son mayores que 0.5 milisegundos, lo que indica que hay una diferencia significativa en el tiempo de ejecución entre los algoritmos Quicksort y Bubblesort, y entre Bubblesort y Mergesort, pero no entre Quicksort y Mergesort.

finalmente se puede decir que bubblesort es el algoritmo más lento, seguido por mergesort y finalmente quicksort, que es el más rápido de los tres.



