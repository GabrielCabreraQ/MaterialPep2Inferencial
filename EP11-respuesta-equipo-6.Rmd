---
title: "EP11-respuesta-equipo-6"
output: html_document
date: "2025-06-12"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
library(ggplot2)
library(dplyr)
library(car)
library(leaps)
library(caret)
library(pROC)
```

Se realizó la carga de datos y se calculó el IMC y la variable
dicotómica EN (estado nutricional) de acuerdo al valor de IMC de cada
persona. Se consideró sobrepeso cuando el IMC es mayor o igual a 23.2, y
no sobrepeso cuando es menor a este valor. La variable EN toma el valor
1 para sobrepeso y 0 para no sobrepeso. Finalmente, se añadió la
variable EN al conjunto de datos original.

```{r}
data = read.csv2("EP09 Datos.csv",sep = ";")
peso = data$Weight
altura = data$Height
imc = peso/(altura/100)^2
data = cbind(data,imc)
en = imc
for (i in imc) {
  if(i>=23.2){
    en[en == i] = 1
  } else {
    en[en == i] = 0
  }
}
#1: sobrepeso 0: no sobrepeso
data = cbind(data,en)
data$en = factor(data$en)
```

### Seleccionar una muestra de 100 personas, asegurando que la mitad tenga estado nutricional “sobrepeso” y la otra mitad “no sobrepeso”.

```{r}
set.seed(19647)
muestra = data %>% group_by(en) %>% sample_n(50)
muestra = muestra[sample(nrow(muestra)), ]  #desordena la muestra para que los valores de EN no estén ordenados

```

### Usando las herramientas del paquete leaps, realizar una búsqueda exhaustiva para seleccionar entre dos y ocho predictores que ayuden a estimar la variable Peso (Weight), obviamente sin considerar las nuevas variables IMC ni EN, y luego utilizar las funciones del paquete caret para construir un modelo de regresión lineal múltiple con los predictores escogidos y evaluarlo usando bootstrapping.

```{r}
set.seed(19647)
variables_predictoras = colnames(muestra)
variables_predictoras = setdiff(variables_predictoras, c("Weight", "imc", "en"))

data_exaustiva = muestra[, c("Weight",variables_predictoras)]
combinaciones = regsubsets(Weight ~ ., data = data_exaustiva, nbest = 1, nvmax = 8, method = "exhaustive")

#Graficar resultados
plot(combinaciones) 

#Extraer los mejores subconjuntos 

resumen_combinaciones <- summary(combinaciones) 

i_bic_minimo <- which.min(resumen_combinaciones[["bic"]])
i_r2a_maximo <- which.max(resumen_combinaciones[["adjr2"]])

mejor_comb_bic <- resumen_combinaciones[["which"]][i_bic_minimo, ]
mejor_comb_r2a <- resumen_combinaciones[["which"]][i_r2a_maximo, ]

# Extraer las variables seleccionadas
comb_mejor_bic <- names(mejor_comb_bic[mejor_comb_bic == TRUE])[-1]  # Exclude intercept
comb_mejor_r2a <- names(mejor_comb_r2a[mejor_comb_r2a == TRUE])[-1]  # Exclude intercept

# Mostrar mejores modelos

cat("Mejores predictores (BIC):", comb_mejor_bic, "\n")
cat("Mejores predictores (R2 adjusted):", comb_mejor_r2a, "\n")

# data para entrenamiento con los mejores predictores, acá se encuentran las 100 observaciones y solo los mejores predictores
train_r2a <- muestra[, c("Weight", comb_mejor_r2a)]

# Definir control de entrenamiento para bootstrapping
train_control <- trainControl(method = "boot", number = 1000)


# Entrenar regresión lineal
modelo_mejor_r2a <- train(Weight ~ ., data = train_r2a, 
                          method = "lm", 
                          trControl = train_control)
print(modelo_mejor_r2a)

# Extraer y mostrar resultados del modelo
resultados <- modelo_mejor_r2a$results
cat("RMSE ", resultados$RMSE, "\n")
cat("R-squared:", resultados$Rsquared, "\n")

summary(modelo_mejor_r2a)

```
Se obtuvo el mejor modelo de regresión lineal múltiple con los siguientes predictores: `Height`, `Waist.Girth`, `Forearm.Girth`, `Chest.Girth`, `Knee.Girth`, `Hip.Girth`, `Thigh.Girth` y `Biiliac.diameter`. El modelo tiene un RMSE de 2328738 y un R-squared ajustado de 0.9695214, lo que indica un buen ajuste del modelo a los datos. A continuación se realizará el estudio de confiabilidad y poder de predicción del modelo obtenido.

### Evaluación de confiabilidad y poder de predicción para el modelo RLM obtenido en parte 3)

### 1. La variable de salida/respuesta debe ser continua y cuantitativa.
### 2. Los predictores deben ser cuantitativos o dicotómicos.
### 3. Los predictores deben tener algun grado de variabilidad, es decir no son constantes

Se cumple que la variable de salida/respuesta es continua y
cuantitativa, ya que la variable `Weight` (Peso) es numérica y puede
tomar cualquier valor dentro de un rango. Se cumple que los predictores
son cuantitativos o dicotómicos, ya que las variables seleccionadas como
predictores son todas numéricas y no hay variables categóricas. Se
cumple que los predictores tienen algún grado de variabilidad, ya que
todas las variables seleccionadas como predictores tienen varianza
distinta de cero.

```{r}
#Codigo respuesta 1.
var(muestra$Weight)
is.numeric(muestra$Weight)

#Codigo respuesta 2.

var(muestra$Height)
is.numeric(muestra$Height)
var(muestra$Waist.Girth)
is.numeric(muestra$Waist.Girth)
var(muestra$Forearm.Girth)
is.numeric(muestra$Forearm.Girth)
var(muestra$Chest.Girth)
is.numeric(muestra$Chest.Girth)
var(muestra$Knee.Girth)
is.numeric(muestra$Knee.Girth)
var(muestra$Hip.Girth)
is.numeric(muestra$Hip.Girth)
var(muestra$Thigh.Girth)
is.numeric(muestra$Thigh.Girth)
var(muestra$Biiliac.diameter)
is.numeric(muestra$Biiliac.diameter)

```

### 4. Cada predictor debe estar relacionado linealmente con la respuesta.

### 5. La distribución de los residuos debe ser cercana a la normal centrada en cero.

### 6. La variabilidad de los residuos debe ser constante (homocedasticidad).

Analizando los gráficos obtenidos, notamos que existen predictores que no siguen una distribución lineal con la variable de respuesta, en este caso tenemos las variables Biiliac.diameter, Hip.Girth, Chest.Girth y Knee.Girth. Por lo que se evaluará con otras pruebas si es necesario la eliminacion de estas variables o no, con el propósito de encontrar el mejor modelo posible. Por otra parte, los residuos del modelo siguen una distribución normal centrada en cero, ya que el gráfico Q-Q muestra que los puntos se alinean con la línea diagonal, lo que indica que los residuos son aproximadamente normales. 
Por ultimo el resultado entregado por el test de homoscedasticidad indica que la variabilidad de los residuos es constante, dado que el p-valor es mayor a 0.05.
```{r}
set.seed(19647)

modelofinal <- lm(Weight ~ ., data = train_r2a)

summary(modelofinal)

#Linealidad de los predictores
residualPlots(modelofinal)
marginalModelPlots(modelofinal)

#Normalidad de los residuos

qqPlot(modelofinal)

#Homoscedasticidad de los residuos

ncvTest(modelofinal) 

```


### 7. Los residuos deben ser independientes entre sí.

El test de Durbin-Watson indica que los residuos no son independientes entre sí, ya que el p-value obtenido es menor a 0.05. Esto suguiere que rechaza la hipótesis nula de independencia de los residuos. Además, el valor de Durbin-Watson es cercano a 2, lo que indica una correlación positiva entre los residuos. Esto puede ser un problema en el modelo, ya que la independencia de los residuos es una suposición clave en la regresión lineal.
```{r}
set.seed(19647)
durbinWatsonTest(modelofinal)

```
### 8. No debe existir multicolinealidad entre los predictores.

El valor entregado por la funcion VIF indica que exite multicolinealidad entre los predictores del modelo final obtenido, ya que el VIF de algunos de ellos se encuentra en un rango entre 5 y 10, lo cual es una multicolinealidad preocupante que podría afectar significativamente los resultados. Dado esto, se aplicarán medidas correctivas para abordar este problema, como la eliminación de variables altamente correlacionadas o la combinación de variables para reducir la multicolinealidad. Se eliminará en primera instancia la variable Hip.Girth, ya que este predictor tiene relación con la variable Billiac.diameter. Los demás predictores redijeron considerablemente, sin embargo, Chest.Girth sigue entregando un valor alto, por lo cual se procederá a su eliminación.


```{r}
set.seed(19647)
cat("VIF de los predictores del modelo final obtenido:\n")
vif(modelofinal)

modelofinaltemp2 <- update(modelofinal, . ~ . - Hip.Girth)
cat("Nuevo VIF luego de eliminar el predictor Hip.Girth:\n")
vif(modelofinaltemp2)

modelofinaltemp3 <- update(modelofinaltemp2, . ~ . - Chest.Girth)
cat("Nuevo VIF luego de eliminar el predictor Chest.Girth:\n")

vif(modelofinaltemp3)

cat("Summary del nuevo modelo final obtenido tras la eliminacion de pred\n")

summary(modelofinaltemp3)
```

Luego de la corrección del modelo tras la eliminación de los predictores con multicolinealidad, se tiene que los predictores finales se encuentran en un rango entre 1 y 5 de valor VIF, lo cual suguiere una multicolinealidad moderada que puede afectar moderadamente los resultados, pero que no son de gran preocupación. Al aplicar el test de Durbin-Watson al nuevo modelo final, se observa que los residuos del modelo corregido son independientes entre sí, ya que el p-value es mayor a 0.05. Esto sugiere que no hay evidencia suficiente para rechazar la hipótesis nula de independencia de los residuos.

```{r}
set.seed(19647)
dwt(modelofinaltemp3)
```
### 9. Los valores atípicos no deben influir en el modelo de manera significativa.

El umbral crítico para identificar valores atípicos es 4/n, donde n es el número de observaciones. En este caso, n = 100, por lo que el umbral crítico es 0.04. Las observaciones 23 y 84 se encuentran por sobre el humbral crítico, lo que indica que son valores atípicos. En cuanto a los valores Hat, se tiene que el límite superior es 2*(k+1)/n, donde k es el número de predictores. En este caso, k = 6, por lo que el límite superior es 0.14. Las observaciones 31 y 34 se encuentran por sobre el límite superior, lo que indica que son valores influyentes. Por lo tanto, se tienen 2 valores atípicos y 2 valores influyentes en el modelo final obtenido, lo cual representan el 4% de las observaciones, lo que es un porcentaje aceptable. Por lo tanto, no se eliminarán del modelo final obtenido.

```{r}

influencePlot(modelofinaltemp3)

```
### Evaluar el poder predictivo del modelo final obtenido.
Finalmente evaluaremos el poder predictivo del modelo, para esto
tendremos una muestr asimilar a la de entrenamiento, 100 observaciones
con 50 valores 1 y 50 valores 0 de la variable EN, y con los mismos
predictores que el modelo final obtenido.

```{r}

# Crear una muestra de 100 observaciones con 50 de cada estado nutricional
set.seed(19647)

muestra_pred <- data %>% group_by(en) %>% sample_n(50)
muestra_pred <- muestra_pred[sample(nrow(muestra_pred)), ]

# Seleccionar las mismas variables predictoras que el modelo final
predictores_finales <- names(coef(modelofinaltemp3))[-1]  # Excluye intercepto


test_data <- muestra_pred[, c("Weight", predictores_finales)]

predicciones <- predict(modelofinaltemp3, newdata = test_data)


# Predecir con los datos no utilizados
predicciones <- predict(modelofinaltemp3, newdata = test_data)
# Agregar las predicciones al data frame de los datos no utilizados
test_data$Predicciones <- predicciones
# Mostrar las predicciones
print(test_data[, c("Weight", "Predicciones")])
# Calcular el error cuadrático medio (MSE)
mse <- mean((test_data$Weight - test_data$Predicciones)^2)
# Calcular el error cuadrático medio (RMSE)
rmse <- sqrt(mse)
cat("RMSE del modelo final:", rmse, "\n")

```
El valor obtenido de RMSE es 2.247639, por otra parte, el RMSE obtenido en el modelo de entrenamiento fue de 2.328738, lo que indica que el modelo final tiene un poder predictivo similar al del modelo de entrenamiento. Esto sugiere que el modelo final es capaz de generalizar bien a nuevos datos y tiene un buen poder predictivo.

#### Usando RFE, construir un modelo de regresión logística múltiple para la variable EN que incluya el conjunto de predictores, entre dos y seis, que entregue la mejor curva ROC y que utilice validación cruzada dejando uno fuera para evitar el sobreajuste (obviamente no se debe considerar las variables Peso, Estatura –Weight y Height respectivamente– ni IMC).
```{r}
set.seed(19647)

# Seleccionar predictores y variable respuesta
predictores_en = setdiff(colnames(muestra), c("imc", "en", "Weight", "Height"))
x_en = muestra[, predictores_en, drop = FALSE]

# Convertir variable respuesta a factor con nombres válidos
y_en = factor(muestra$en,
               levels = c(0, 1),
               labels = c("No_EN", "Si_EN"))  

# Control para el RFE
ctrl_loocv <- rfeControl(
  functions = lrFuncs,           
  method = "LOOCV",             
  verbose = FALSE,
  returnResamp = "final"
)

# Train para RFE
trainp5 = trainControl(
  method = "none",               
  classProbs = TRUE,            
  summaryFunction = twoClassSummary
)

# cantidad de predictores a usar en RFE
subset_sizes = 2:6

# RFE
rfe_resultados <- suppressWarnings(rfe(
  x = x_en,
  y = y_en,
  sizes = subset_sizes,
  rfeControl = ctrl_loocv,
  trControl = trainp5,
  metric = "ROC"
))

print(rfe_resultados)
plot(rfe_resultados, type = c("g", "o"))
cat("\nPredictores seleccionados:", predictors(rfe_resultados), "\n")

# Entrenar modelo final con predictores seleccionados
mejores_predictores_p5 <- predictors(rfe_resultados)
modelo_final_p5 <- glm(y_en ~ ., 
                   data = data.frame(x_en[, mejores_predictores_p5, drop = FALSE], y_en),
                   family = binomial)

cat("\n--- Resumen del Modelo Final ---\n")
summary(modelo_final_p5)

# Calcular probabilidades y clase predicha
probabilidades <- predict(modelo_final_p5, type = "response")
prediccion_clase <- factor(ifelse(probabilidades > 0.5, "Si_EN", "No_EN"),
                           levels = c("No_EN", "Si_EN"))

# Calcular curva ROC y AUC
roc_curve <- roc(response = y_en, predictor = probabilidades, levels = c("No_EN", "Si_EN"))
auc_value <- auc(roc_curve)

# Mejorar gráfico de curva ROC
plot(roc_curve, 
     main = "Curva ROC del Modelo Final", 
     col = "blue", 
     lwd = 2,
     legacy.axes = TRUE)  # Eje x: 0-1 en lugar de 1-0
grid()
abline(a = 0, b = 1, lty = 2, col = "gray")  # Línea de referencia
legend("bottomright", 
       legend = paste("AUC =", round(auc_value, 3)),
       col = "blue", 
       lwd = 2)

# Calcular matriz de confusión

conf_matrix <- confusionMatrix(prediccion_clase, y_en, positive = "Si_EN")
cat("\n--- Matriz de Confusión ---\n")
print(conf_matrix)

umbral_optimo <- coords(roc_curve, "best", ret = "threshold", best.method = "youden")$threshold
cat("\nUmbral óptimo (Youden):", round(umbral_optimo, 3), "\n")

prediccion_optima <- factor(ifelse(probabilidades > umbral_optimo, "Si_EN", "No_EN"),
                            levels = c("No_EN", "Si_EN"))

conf_matrix_optima <- confusionMatrix(prediccion_optima, y_en, positive = "Si_EN")


# Mostrar métricas clave

cat("\n--- Métricas con Umbral 0.5 ---\n")
cat("Exactitud:", round(conf_matrix$overall['Accuracy'], 3), "\n")
cat("Sensibilidad:", round(conf_matrix$byClass['Sensitivity'], 3), "\n")
cat("Especificidad:", round(conf_matrix$byClass['Specificity'], 3), "\n")
cat("Precisión:", round(conf_matrix$byClass['Precision'], 3), "\n")
cat("F1-score:", round(conf_matrix$byClass['F1'], 3), "\n")

cat("\n--- Métricas con Umbral Óptimo (", round(umbral_optimo, 3), ") ---\n")
cat("Exactitud (Accuracy):", round(conf_matrix_optima$overall['Accuracy'], 3), "\n")
cat("Sensibilidad (Recall):", round(conf_matrix_optima$byClass['Sensitivity'], 3), "\n")
cat("Especificidad:", round(conf_matrix_optima$byClass['Specificity'], 3), "\n")
cat("Precisión:", round(conf_matrix_optima$byClass['Precision'], 3), "\n")
cat("F1-score:", round(conf_matrix_optima$byClass['F1'], 3), "\n")


```
### Pronunciarse sobre la confiabilidad y el poder predictivo de los modelos obtenidos.

### Relación lineal entre predictores
Notamos que los predictores del modelo final obtenidos con RFE siguen una relación lineal con la variable de respuesta, ya que los gráficos de residuos muestran que los residuos son aproximadamente lineales y no presentan patrones evidentes. Esto sugiere que los predictores seleccionados son adecuados para el modelo de regresión logística.
```{r}

residualPlots(modelo_final_p5, 
              fitted = FALSE)

```

### Multicolinealidad
Notemos que los valores de multicolinealidad de los predictores del modelo final obtenido con RFE son menores a 5, inclusive, muy cercanos a 1, lo que indica que no existe multicolinealidad entre los predictores. 
```{r}
vif(modelo_final_p5)

```
### Residuos independientes entre si 
El test de Durbin-Watson indica que los residuos del modelo final obtenido con RFE son independientes entre sí, ya que el p-value es mayor a 0.05. Esto sugiere que no hay evidencia suficiente para rechazar la hipótesis nula de independencia de los residuos. Además, que el valor durbin-watson es cercano a 2, lo que indica una correlación positiva entre los residuos. Esto sugiere que el modelo final obtenido con RFE cumple con el supuesto de independencia de los residuos.
```{r}
durbinWatsonTest(modelo_final_p5)

```
### Los datos no se encuentran influenciados
Notamos que no existen valores atípicos ni valores influyentes en el modelo final obtenido con RFE, ya que el gráfico de influencia muestra que hay puntos que se encuentren por encima del umbral crítico de 4/n= 0.04, estos son 21, 35, 54 y 55. además, los valores Hat están pro encima del límite superior de 2*(k+1)/n. = 0.08 están los puntos 9 y 5. Esto suguiere que los datos se encuentran influenciados por estos puntos, pero no de manera significativa, ya que el porcentaje de puntos influyentes es menor al 5% del total de observaciones. Por lo tanto, no se eliminarán del modelo final obtenido.
```{r}

influencePlot(modelo_final_p5)

```
### Información incompleta
hay que ver que los predictores tienen al menos 20 observaciones por cada nivel de la variable de respuesta, lo que indica que no hay problemas de información incompleta en el modelo final obtenido con RFE.
```{r}
predictores <- predictors(modelo_final_p5)
for (pred in predictores) {
  cat("Variable:", pred, "\n")
  cat("Número de observaciones por nivel de la variable de respuesta:\n")
  print(table(muestra[[pred]]))
  cat("\n")
}

```
### Separación perfecta
En los gráficos de residuos del modelo final obtenido con RFE, se puede observar que las rectas ajustadas no están desviadas de la curva local de ajuste de los datos, lo que indica que no hay separación perfecta. Esto sugiere que el modelo es capaz de capturar la relación entre los predictores y la variable de respuesta sin problemas de separación perfecta.


### Conclusión del modelo parte final RFE
El modelo de regresión logística múltiple obtenido con RFE cumple con los supuestos necesarios para ser considerado confiable y con un buen poder predictivo. Los predictores seleccionados son adecuados, no hay multicolinealidad significativa, los residuos son independientes y no hay problemas de separación perfecta. Además, el modelo muestra un buen rendimiento en términos de AUC y métricas de clasificación. Por lo tanto, se puede concluir que el modelo es confiable y tiene un buen poder predictivo para la variable EN.